{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Selene\n",
    "\n",
    "This tutorial explores the core components of Selene, and should teach you everything you need to know to train a simple model on biological sequence data.\n",
    "Before starting this tutorial, you need to install Selene.\n",
    "Instructions for installation are available [here](https://selene.flatironinstitute.org/installation.html).\n",
    "Lastly, if you are not familiar with neural networks, we recommend reading through this [introductory PyTorch tutorial on neural networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
    "In the simplest case, we train a neural network as follows:\n",
    "\n",
    "1. Construct our neural network, which should be a [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) object\n",
    "2. Load the training data and divide it into training and validation sets\n",
    "3. Iterate over the training set\n",
    "4. Compute and backpropagate the training loss after each iteration\n",
    "5. Save the model weights at specified intervals\n",
    "6. Compute and report the loss on the validation set at specified intervals\n",
    "7. Compute and report the loss on the validation set after training is complete\n",
    "\n",
    "In this case, much of our work is already done for us.\n",
    "In fact, we do not actually need to write any code besides our model and a configuration file.\n",
    "\n",
    "## Download the data\n",
    "\n",
    "First, we need to download the data\n",
    "\n",
    "TODO\n",
    "\n",
    "## Command line arguments\n",
    "\n",
    "Selene uses a limited number (two to be precise) of command line arguments.\n",
    "The first of these is the positional parameter for the configuration file, which we will discuss in more detail in the following section.\n",
    "The second argument is the optional named argument for the learning rate, specified with `--lr`.\n",
    "The learning rate only needs to be specified when Selene is training a model, and is ignored in all other circumstances.\n",
    "\n",
    "## Configuration file syntax\n",
    "\n",
    "The configuration file is a [YAML file](https://en.wikipedia.org/wiki/YAML) that specifies the majority of the runtime parameters for Selene.\n",
    "In general, a YAML file with keys `key1` and `key2` taking values `val1` and `val2` would look like such:\n",
    "\n",
    "```YAML\n",
    "---\n",
    "key1: val1\n",
    "key2: val2\n",
    "...\n",
    "```\n",
    "\n",
    "For training a new network, there are a few keys that we must include in this YAML file, which we will discuss later.\n",
    "\n",
    "The following sections explain each of these parameters in some detail.\n",
    "However, we first need to discuss the syntax for our configuration file.\n",
    "We discuss each of the argument types for configuration files below.\n",
    "\n",
    "### Literal arguments\n",
    "\n",
    "The simplest configuration arguments are literals.\n",
    "To specify a learning rate of `0.01`, and that we would like to evaluate test metric performance and not save the datasets, we would include the following lines in our configuration file:\n",
    "```YAML\n",
    "lr: 0.01\n",
    "evaluate_on_test: True\n",
    "save_datasets: True\n",
    "```\n",
    "\n",
    "### List arguments\n",
    "\n",
    "After literals, lists arguments like `ops` are the next simplest type of configuration parameter.\n",
    "Syntactically, list arguments are very similar to the python lists that they represent.\n",
    "For instance, to specify `ops` as the Python list below:\n",
    "```python\n",
    "ops = [\"train\"]\n",
    "```\n",
    "we would write the following line in our configuration file:\n",
    "```YAML\n",
    "ops: [train]\n",
    "```\n",
    "\n",
    "### Dictionary arguments\n",
    "\n",
    "The next type of argument we need is a dictionary.\n",
    "Like lists, dictionaries in the configuration file are very similar to their Python equivalents.\n",
    "For instance, if the `model` configuration were written as a dictionary in Python, it might look something like the following:\n",
    "```python\n",
    "model = {\"file\": \"/path/to/deepsea.py\",\n",
    "         \"class\": \"DeepSEA\",\n",
    "         \"sequence_length\": 1000\n",
    "         \"n_classes_to_predict\": 919,\n",
    "         \"non_strand_specific\": {\n",
    "             \"use_module\": True,\n",
    "             \"mode\": \"mean\"\n",
    "             }\n",
    "         }\n",
    "```\n",
    "Now, to write this in the configuration file, we simply include the following lines:\n",
    "```YAML\n",
    "model: {\n",
    "    file: /path/to/deepsea.py,\n",
    "    class: DeepSEA,\n",
    "    sequence_length: 1000,\n",
    "    n_classes_to_predict: 919,\n",
    "    non_strand_specific: {\n",
    "        use_module: True,\n",
    "        mode: mean\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Function arguments \n",
    "\n",
    "In addition to the types we've just discussed, Selene's configuration accept python function calls.\n",
    "For instance, let's say we want to specify the value of the `features` argument for `train_model`, which takes a list of strings and specifies the names of the values we are predicting with our model.\n",
    "One option would be to write the list of strings into the configuration file, but this might take a long time if this list is very long.\n",
    "If we were using Python, we would just read the list of feature names the following:\n",
    "```python\n",
    "import selene\n",
    "features = selene.utils.load_features_list(input_path=\"features_list.txt\")\n",
    "```\n",
    "Fortunately, we can use function the function call arguments to include this in our configuration file.\n",
    "Specifically, we would write the following in our configuration file:\n",
    "```YAML\n",
    "features: !obj.selene.utils.load_features_list {\n",
    "    input_path: \"features_list.txt\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Training a model and analyzing sequences with it\n",
    "\n",
    "To train or analyze sequences with a model, we first specify the configuration file and then we execute `selene` from the command line.\n",
    "The first section provides an overview of all the requirements for training a model with Selene.\n",
    "The second section covers the arguments used to evaluate sequences with a trained model.\n",
    "We recommend opening the included `train.yaml` and `analyze.yaml` configuration files and following along in them while reading through these sections.\n",
    "\n",
    "### Configuration file arguments for training\n",
    "Before running Selene from the command line, we need to specify its runtime parameters in a configuration file.\n",
    "Specifically, we need to include the following:\n",
    "\n",
    "| key              | definition |\n",
    "|------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| ops              | list of operations to execute with Selene |\n",
    "| model            | dict containing the configuration parameters for the model we intend to train.\n",
    "| sampler          | a subclass of selene.samplers.Sampler |\n",
    "| train_model      | a subclass of selene.TrainModel |\n",
    "| lr               | a floating point value for the learning rate, if we do not want to specify it in the command line arguments |\n",
    "| evaluate_on_test | a boolean specifying whether we should calculate performance metrics on held out test data |\n",
    "| save_datasets    | a boolean specifying if we would like to write the training/validation/test data to file                   |\n",
    "\n",
    "#### ops\n",
    "\n",
    "Selene currently supports the `train` and `analyze` operations, and allows chaining of operations by simply adding them to the `ops` list in the configuration file.\n",
    "For instance, to train a model and then use it to analyze some data, you would include the following line in the configuration file:\n",
    "```YAML\n",
    "ops: [train, analyze]\n",
    "```\n",
    "To only train a model, we would just write the following:\n",
    "```YAML\n",
    "ops: [train]\n",
    "```\n",
    "\n",
    "#### model\n",
    "\n",
    "In this tutorial, we will use the neural network from [DeepSEA](http://deepsea.princeton.edu), which models chromatin properties of sequences in the non-coding genome.\n",
    "The class for this model, `DeepSEA`, is specified in the `deepsea.py` file from earlier.\n",
    "The model should follow all of the [normal rules for specifying a `torch.nn.Module`](https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html), with two exceptions.\n",
    "First, the file with the model class should include a method called `criterion` that returns the object to use for the [PyTorch loss function](https://pytorch.org/docs/master/nn.html#loss-functions).\n",
    "In `deepsea.py`, this is defined as follows:\n",
    "```python\n",
    "def criterion():\n",
    "    return torch.nn.BCELoss()\n",
    "```\n",
    "Second, we must define a method called `get_optimizer` that takes a learning rate, and returns the [optimization function](https://pytorch.org/docs/master/optim.html) and its parameters.\n",
    "The return value should be a 2-tuple, where the first element is the optimizer class, and the second element is a `dict` containing the keyword arguments to use when constructing the optimizer.\n",
    "In `deepsea.py`, this is specified as follows:\n",
    "```python\n",
    "def get_optimizer(lr):\n",
    "    return (torch.optim.SGD, {\"lr\": lr, \"weight_decay\": 1e-6, \"momentum\": 0.9})\n",
    "```\n",
    "Note that, to allow specifying the learning rate at the command line, you should include the passed `lr` argument in the `dict` of keyword arguments.\n",
    "\n",
    "#### sampler\n",
    "\n",
    "The `sampler` argument specifies how Selene will sample its training data.\n",
    "The value for `sampler` should be a function-type argument, and the function needed to construct an object that is a subclass of `selene.samplers.Sampler`. \n",
    "The specific arguments for the sampler's construction will vary by class, so it is important to check the class definitions and documentation when specifying them.\n",
    "For the example, we will use the following configuration for the `sampler`:\n",
    "```YAML\n",
    "sampler: !obj:selene.samplers.IntervalsSampler {\n",
    "    reference_sequence: !obj:selene.sequences.Genome {\n",
    "            input_path: hg19.fasta\n",
    "            },\n",
    "    features: !obj:selene.utils.load_features_list {\n",
    "        input_path: distinct_features.txt\n",
    "    },\n",
    "    target_path: target_data.bed.gz\n",
    "    intervals_path: intervals_only.txt,\n",
    "    sequence_length: 1000,\n",
    "    center_bin_to_predict: 200,\n",
    "    test_holdout: [chr8, chr9],\n",
    "    validation_holdout: [chr6, chr7],\n",
    "    feature_thresholds: 0.5,\n",
    "    seed: 127,\n",
    "    mode: \"train\",\n",
    "    save_datasets: []\n",
    "}\n",
    "```\n",
    "\n",
    "#### train_model\n",
    "The `train_model` argument is responsible to specifying many of the parameters for `selene.TrainModel`.\n",
    "The following parameters for `train_model` are automatically generated, and should not be specified in the configuration file:\n",
    "\n",
    "|                |\n",
    "|----------------|\n",
    "| model          |\n",
    "|data_sampler    |\n",
    "|loss_criterion  |\n",
    "|optimizer_class |\n",
    "|optimizer_kwargs|\n",
    "\n",
    "With this in mind, we write the following in our configuration file:\n",
    "```YAML\n",
    "train_model: !obj:selene.TrainModel {\n",
    "    batch_size: 64,\n",
    "    max_steps: 500000,\n",
    "    report_stats_every_n_steps: 16000,\n",
    "    n_validation_samples: 32000,\n",
    "    cpu_n_threads: 32,\n",
    "    use_cuda: False,\n",
    "    data_parallel: False,\n",
    "    logging_verbosity: 2,\n",
    "    output_dir: ./\n",
    "}\n",
    "```\n",
    "\n",
    "#### other arguments\n",
    "\n",
    "There are three additional optional arguments we need when training models: `lr`, `evaluate_on_test`, and `save_datasets`.\n",
    "If you do not want to specify the learning rate in the command line arguments, you can specify it in the configuration file.\n",
    "However, note that Selene will throw an exception and crash if `lr` is not included in the configuration file or specified in the command line arguments.\n",
    "If we want to specify it in the configuration file, we can include the following lines:\n",
    "```YAML\n",
    "lr: 0.01\n",
    "```\n",
    "If you want your model to evaluate its performance on the test data after it has completed its training, you can use the `evaluate_on_test`.\n",
    "If this argument is not included in the configuration file and set as `True`, the model performance will not be evaluated on the testing data.\n",
    "To set the `evaluate_on_test` argument to `True`, you would include the following lines in your configuration file:\n",
    "```YAML\n",
    "evaluate_on_test: True\n",
    "```\n",
    "Lastly, there is the `save_datasets` argument, which will let us save our data to file if we are using a sampler that generates \n",
    "Like the `evaluate_on_test` argument, `save_datasets` will be set to `False` if it is not included in the configuration file.\n",
    "To specify that we would like to save the datasets, we would include the following in our configuration file:\n",
    "```YAML\n",
    "save_datasets: True\n",
    "```\n",
    "\n",
    "### Configuration file arguments for analyzing sequences\n",
    "\n",
    "TODO\n",
    "\n",
    "#### TODO\n",
    "\n",
    "### Running it\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201b070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _format_feature_dataset(filepath, feature):\n",
    "    file_df = pd.read_table(filepath, header=None, usecols=[0, 1, 2, 3])\n",
    "    n_rows, _ = file_df.shape\n",
    "    file_df = file_df.assign(feature=pd.Series([feature] * n_rows))\n",
    "    file_df = file_df.assign(metadata_index=pd.Series([index] * n_rows))\n",
    "    return file_df\n",
    "\n",
    "\n",
    "def metadata_to_dict(filepath):\n",
    "    metadata = {}\n",
    "    with open(filepath, \"r\") as fh:\n",
    "        for line in fh:\n",
    "            dataset, ds_info = line.split(\"\\t\")\n",
    "            info_dict = {}\n",
    "            key_vals = ds_info.split(\";\")\n",
    "            for kv in key_vals:\n",
    "                kv = kv.strip()\n",
    "                key, val = kv.split(\"=\")\n",
    "                info_dict[key] = val\n",
    "            metadata[dataset] = info_dict\n",
    "    return metadata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0521a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = \"/home/tt419/Projects/DeepLearning/PhDeep/data/ENCODE_ftp/label_names.txt\"\n",
    "# http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeOpenChromDnase/\n",
    "ENCODE_DNase = \"/home/tt419/Projects/DeepLearning/PhDeep/data/ENCODE_ftp/DNAse/\"\n",
    "# http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeAwgTfbsUniform/\n",
    "ENCODE_TF = \"/home/tt419/Projects/DeepLearning/PhDeep/data/ENCODE_ftp/TFChip/\"\n",
    "# https://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/\n",
    "Roadmap_Epi = \"/home/tt419/Projects/DeepLearning/PhDeep/data/Selene/chromatin_profiles/Roadmap_Epigenomics/\"\n",
    "    \n",
    "ENC_DNase_file = os.path.join(\n",
    "        ENCODE_DNase, \"files_DNAse.txt\")\n",
    "ENC_TF_file = os.path.join(\n",
    "        ENCODE_TF, \"files_TFChip.txt\")\n",
    "Roadmap_file = os.path.join(\n",
    "        Roadmap_Epi,\n",
    "        \"jul2013.roadmapData.qc - \"\n",
    "        \"Consolidated_EpigenomeIDs_summary_Table.tsv\")\n",
    "\n",
    "\n",
    "output_dir = \"/rds-d5/project/who1000/rds-who1000-wgs10k/user/tt419/Selene_data/selene_ftp_output/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e795ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNase_metadata = metadata_to_dict(ENC_DNase_file)\n",
    "TFs_metadata = metadata_to_dict(ENC_TF_file)\n",
    "Roadmap_metadata = pd.read_table(Roadmap_file)\n",
    "Roadmap_metadata.set_index(\"Epigenome ID (EID)\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c71a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique features mapped to number of duplicates\n",
    "deepsea_features = {}\n",
    "# for index, (filename, info) in enumerate(DNase_metadata.items()):\n",
    "#     # just to handle some edge cases\n",
    "#     filename_split = filename.split(\".\")\n",
    "#     if len(filename_split) > 3:\n",
    "#         filename = \"\".join(filename_split[:-2]) + \".narrowPeak.gz\"\n",
    "#     filepath = os.path.join(ENCODE_DNase, filename)\n",
    "#     feature = \"{0}|DNase|{1}\".format(info[\"cell\"], info[\"treatment\"])\n",
    "#     if feature not in deepsea_features:\n",
    "#         deepsea_features[feature] = 0\n",
    "#     deepsea_features[feature] += 1\n",
    "\n",
    "# for index, (filename, info) in enumerate(TFs_metadata.items()):\n",
    "#     # just to handle some edge cases\n",
    "#     filename_split = filename.split(\".\")\n",
    "#     if len(filename_split) > 3:\n",
    "#         filename = \"\".join(filename_split[:-2]) + \".narrowPeak.gz\"\n",
    "#     filepath = os.path.join(ENCODE_DNase, filename)\n",
    "#     feature = \"{0}|{1}|{2}\".format(\n",
    "#         info[\"cell\"], info[\"antibody\"].split('_')[0], info[\"treatment\"])\n",
    "#     if feature not in deepsea_features:\n",
    "#         deepsea_features[feature] = 0\n",
    "#     deepsea_features[feature] += 1\n",
    "    \n",
    "for index, filename in enumerate(os.listdir(Roadmap_Epi)):\n",
    "    if \".narrowPeak.gz\" not in filename:\n",
    "        continue\n",
    "    filepath = os.path.join(Roadmap_Epi, filename)\n",
    "    filename = filename[:-len(\".narrowPeak.gz\")]\n",
    "    EID, info = filename.split(\"-\")\n",
    "\n",
    "    row = Roadmap_metadata.loc[EID]\n",
    "    # handling the edge cases\n",
    "    cell_type = row.get(\"DONOR / SAMPLE ALIAS\")\n",
    "    if cell_type == \"RO01746\":\n",
    "        cell_type = \"Monocytes-CD14+RO01746 \"\n",
    "    if cell_type == \"Osteobl\":\n",
    "        cell_type = \"Osteoblasts\"\n",
    "    if \"hESC-01\" in cell_type:\n",
    "        cell_type = \"H1-hESC\"\n",
    "\n",
    "    if info == \"H2A.Z\":\n",
    "        info = \"H2AZ\"\n",
    "\n",
    "    feature = \"{0}|{1}|None\".format(cell_type, info)\n",
    "    if feature not in deepsea_features:\n",
    "        deepsea_features[feature] = 0\n",
    "    deepsea_features[feature] += 1\n",
    "    \n",
    "all_features_with_dups = []\n",
    "all_features = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_to_concat = []\n",
    "\n",
    "# ENCODE DNase features\n",
    "for index, (filename, info) in enumerate(DNase_metadata.items()):\n",
    "    # just to handle some edge cases\n",
    "    filename_split = filename.split(\".\")\n",
    "    if len(filename_split) > 3:\n",
    "        filename = \"\".join(filename_split[:-2]) + \".narrowPeak.gz\"\n",
    "    filepath = os.path.join(ENCODE_DNase, filename)\n",
    "    feature = \"{0}|DNase|{1}\".format(info[\"cell\"], info[\"treatment\"])\n",
    "    if feature not in deepsea_features:\n",
    "        continue\n",
    "    all_features_with_dups.append(feature)\n",
    "\n",
    "    if feature in deepsea_features and deepsea_features[feature] > 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "        feature = \"{0}|{1}\".format(feature, deepsea_features[feature])\n",
    "    elif feature in deepsea_features and deepsea_features[feature] == 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "    elif feature in deepsea_features and deepsea_features[feature] <= 0:\n",
    "        continue\n",
    "    all_features.append(feature)\n",
    "    dfs_to_concat.append(_format_feature_dataset(\n",
    "        filepath, feature))\n",
    "\n",
    "DNase_agg = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "DNase_agg.sort_values([0, 1, 2], ascending=True, inplace=True)\n",
    "\n",
    "print(DNase_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0227098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0      1      2  3             feature  metadata_index\n",
      "4261851   chr1  10073  10329  .    K562|ZBTB33|None             246\n",
      "3548416   chr1  10144  10263  .   HepG2|ZBTB33|None             204\n",
      "5683966   chr1  10149  10413  .  H1-hESC|CEBPB|None             343\n",
      "11985525  chr1  16110  16390  .   HCPEpiC|CTCF|None             662\n",
      "3721671   chr1  16118  16362  .    K562|CTCF|None|3             213\n"
     ]
    }
   ],
   "source": [
    "dfs_to_concat = []\n",
    "\n",
    "# ENCODE TF features\n",
    "for index, (filename, info) in enumerate(TFs_metadata.items()):\n",
    "    filepath = os.path.join(ENCODE_TF, filename)\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    "    feature = \"{0}|{1}|{2}\".format(\n",
    "        info[\"cell\"], info[\"antibody\"].split('_')[0], info[\"treatment\"])\n",
    "    if feature not in deepsea_features:\n",
    "        continue\n",
    "    all_features_with_dups.append(feature)\n",
    "    if feature in deepsea_features and deepsea_features[feature] > 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "        feature = \"{0}|{1}\".format(feature, deepsea_features[feature])\n",
    "    elif feature in deepsea_features and deepsea_features[feature] == 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "    elif feature in deepsea_features and deepsea_features[feature] <= 0:\n",
    "        continue\n",
    "\n",
    "    all_features.append(feature)\n",
    "    dfs_to_concat.append(_format_feature_dataset(\n",
    "        filepath, feature))\n",
    "\n",
    "\n",
    "\n",
    "ChIP_agg = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "ChIP_agg.sort_values([0, 1, 2], ascending=True, inplace=True)\n",
    "print(ChIP_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147628d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b248cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 815\n"
     ]
    }
   ],
   "source": [
    "full_aggregate_file = pd.concat(\n",
    "    [DNase_agg, ChIP_agg], ignore_index=True) # , EID_agg deleted the EID_agg bit here, as we don't have the Roadmap Epigenomics right now\n",
    "full_aggregate_file.columns = [\"chrom\", \"start\", \"end\", \"strand\", \"feature\", \"metadata_index\"]\n",
    "output_file = os.path.join(output_dir, \"selene_fullFeatures_unsorted.bed\")\n",
    "with open(output_file, 'a+') as file_handle: #changed to append, so that I can create it in steps\n",
    "    for row in full_aggregate_file.itertuples():\n",
    "        file_handle.write(\"{0}\\t{1}\\t{2}\\t{3}\\n\".format(row.chrom, row.start, row.end, row.feature))\n",
    "\n",
    "print(\"Total number of features: {0}\".format(len(all_features)))\n",
    "output_features = os.path.join(output_dir, \"distinct_features.txt\")\n",
    "with open(output_features, 'a+') as file_handle: #changed to append, so that I can create it in steps\n",
    "    features = sorted(all_features)\n",
    "    for f in features:\n",
    "        file_handle.write(\"{0}\\n\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6398fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DNase_agg\n",
    "del ChIP_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db592432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs_to_concat = []\n",
    "EID_features = []\n",
    "# Roadmap Epigenomic features (DNase, histone marks)\n",
    "for index, filename in enumerate(os.listdir(Roadmap_Epi)):\n",
    "    if \".narrowPeak.gz\" not in filename:\n",
    "        continue\n",
    "    filepath = os.path.join(Roadmap_Epi, filename)\n",
    "    filename = filename[:-len(\".narrowPeak.gz\")]\n",
    "    EID, info = filename.split(\"-\")\n",
    "\n",
    "    row = Roadmap_metadata.loc[EID]\n",
    "    # handling the edge cases\n",
    "    cell_type = row.get(\"DONOR / SAMPLE ALIAS\")\n",
    "    if cell_type == \"RO01746\":\n",
    "        cell_type = \"Monocytes-CD14+RO01746 \"\n",
    "    if cell_type == \"Osteobl\":\n",
    "        cell_type = \"Osteoblasts\"\n",
    "    if \"hESC-01\" in cell_type:\n",
    "        cell_type = \"H1-hESC\"\n",
    "\n",
    "    if info == \"H2A.Z\":\n",
    "        info = \"H2AZ\"\n",
    "\n",
    "    feature = \"{0}|{1}|None\".format(cell_type, info)\n",
    "\n",
    "    if feature not in deepsea_features:\n",
    "        continue\n",
    "    all_features_with_dups.append(feature)\n",
    "    if feature in deepsea_features and deepsea_features[feature] > 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "        feature = \"{0}|{1}\".format(feature, deepsea_features[feature] + 1)\n",
    "    elif feature in deepsea_features and deepsea_features[feature] == 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "    elif feature in deepsea_features and deepsea_features[feature] <= 0:\n",
    "        continue\n",
    "    EID_features.append(feature)\n",
    "    all_features.append(feature)\n",
    "    dfs_to_concat.append(_format_feature_dataset(\n",
    "        filepath, feature).sort_values([0, 1, 2], ascending=True))\n",
    "\n",
    "# EID_agg = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "# EID_agg.sort_values([0, 1, 2], ascending=True, inplace=True)\n",
    "# print(EID_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for EID_agg in dfs_to_concat:\n",
    "    full_aggregate_file = EID_agg\n",
    "    full_aggregate_file.columns = [\"chrom\", \"start\", \"end\", \"strand\", \"feature\", \"metadata_index\"]\n",
    "    output_file = os.path.join(output_dir, \"selene_fullFeatures_unsorted.bed\")\n",
    "    with open(output_file, 'a+') as file_handle: #changed to append, so that I can create it in steps\n",
    "        for row in full_aggregate_file.itertuples():\n",
    "            file_handle.write(\"{0}\\t{1}\\t{2}\\t{3}\\n\".format(row.chrom, row.start, row.end, row.feature))\n",
    "\n",
    "print(\"Total number of features: {0}\".format(len(all_features)))\n",
    "output_features = os.path.join(output_dir, \"distinct_features.txt\")\n",
    "with open(output_features, 'a+') as file_handle: #changed to append, so that I can create it in steps\n",
    "    features = sorted(EID_features)\n",
    "    for f in features:\n",
    "        file_handle.write(\"{0}\\n\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ca0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs_to_concat = []\n",
    "EID_features = []\n",
    "# Roadmap Epigenomic features (DNase, histone marks)\n",
    "for index, filename in enumerate(os.listdir(Roadmap_Epi)):\n",
    "    if \".narrowPeak.gz\" not in filename:\n",
    "        continue\n",
    "    filepath = os.path.join(Roadmap_Epi, filename)\n",
    "    filename = filename[:-len(\".narrowPeak.gz\")]\n",
    "    EID, info = filename.split(\"-\")\n",
    "\n",
    "    row = Roadmap_metadata.loc[EID]\n",
    "    # handling the edge cases\n",
    "    cell_type = row.get(\"DONOR / SAMPLE ALIAS\")\n",
    "    if cell_type == \"RO01746\":\n",
    "        cell_type = \"Monocytes-CD14+RO01746 \"\n",
    "    if cell_type == \"Osteobl\":\n",
    "        cell_type = \"Osteoblasts\"\n",
    "    if \"hESC-01\" in cell_type:\n",
    "        cell_type = \"H1-hESC\"\n",
    "\n",
    "    if info == \"H2A.Z\":\n",
    "        info = \"H2AZ\"\n",
    "\n",
    "    feature = \"{0}|{1}|None\".format(cell_type, info)\n",
    "\n",
    "    if feature not in deepsea_features:\n",
    "        continue\n",
    "    all_features_with_dups.append(feature)\n",
    "    if feature in deepsea_features and deepsea_features[feature] > 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "        feature = \"{0}|{1}\".format(feature, deepsea_features[feature] + 1)\n",
    "    elif feature in deepsea_features and deepsea_features[feature] == 1:\n",
    "        deepsea_features[feature] -= 1\n",
    "    elif feature in deepsea_features and deepsea_features[feature] <= 0:\n",
    "        continue\n",
    "    EID_features.append(feature)\n",
    "    all_features.append(feature)\n",
    "    \n",
    "    full_aggregate_file = _format_feature_dataset(\n",
    "        filepath, feature).sort_values([0, 1, 2], ascending=True)\n",
    "    full_aggregate_file.columns = [\"chrom\", \"start\", \"end\", \"strand\", \"feature\", \"metadata_index\"]\n",
    "    output_file = os.path.join(output_dir, \"selene_fullFeatures_unsorted.bed\")\n",
    "    with open(output_file, 'a+') as file_handle: #changed to append, so that I can create it in steps\n",
    "        for row in full_aggregate_file.itertuples():\n",
    "            file_handle.write(\"{0}\\t{1}\\t{2}\\t{3}\\n\".format(row.chrom, row.start, row.end, row.feature))\n",
    "    \n",
    "# EID_agg = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "# EID_agg.sort_values([0, 1, 2], ascending=True, inplace=True)\n",
    "# print(EID_agg.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P3_conda",
   "language": "python",
   "name": "python3_loc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
